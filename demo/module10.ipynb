{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datascience import *\n",
    "from math import *\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling with Replacement\n",
    "\n",
    "Why do we resample with replacement? How is that different from resample without replacement? \n",
    "\n",
    "Recall that, in bootstrapping, we will resample with replacement the same sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This data are midterm scores from CS61A, Fall 2017\n",
    "scores = Table().read_table(\"scores.csv\")\n",
    "\n",
    "mt1_scores = scores.select(\"MT1 %\")\n",
    "mt1_scores.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the original mean?\n",
    "np.mean(mt1_scores.column(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we sampled withOUT replacement?\n",
    "scores_n = scores.num_rows\n",
    "\n",
    "wo_replacement = mt1_scores.sample(scores_n, with_replacement = False)\n",
    "wo_replacement.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean without replacement, same sample size\n",
    "np.mean(wo_replacement.column(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, what if we sample with replacement?\n",
    "w_replacement = mt1_scores.sample(scores_n, with_replacement = True)\n",
    "w_replacement.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean with replacement, same sample size\n",
    "np.mean(w_replacement.column(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping: What is the average MT1 score?\n",
    "\n",
    "The `scores` dataset is population-level; in other words, it has all of the information for every student in the class. That isn't good for our purpose, since there is no reason for us to do inferential statistics if we have all of the data. \n",
    "\n",
    "(Note: this does not happen very often at all; you'll usually start off with a sample.)\n",
    "\n",
    "Instead, let's imagine we randomly asked a sample of 60 students what they got on MT1. Then, let's use that sample of 60 to estimate what the whole class got on the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(12345) # So we all get the same data\n",
    "\n",
    "class_sample = mt1_scores.sample(60, with_replacement = False)\n",
    "class_sample.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Question 1: Let's practice taking a resample with replacement.\n",
    "one_resample = ...\n",
    "one_resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Did we get some variation?\n",
    "np.mean(class_sample.column(0)) == np.mean(one_resample.column(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2: Resampling with replacement... many times (let's try 1000!)\n",
    "\n",
    "def bootstrap_stats(tbl, repetitions)\n",
    "    \"\"\"\n",
    "    tbl = your data, a 1-column table of numerical scores\n",
    "    repetitions = num bootstrap repetitions/resamples\n",
    "    \"\"\"\n",
    "    # Storage array for each resampled statistic (mean)\n",
    "    bootstrap_stats = ... \n",
    "\n",
    "    # Iterate to create many different resamples, and calculate each individual mean\n",
    "    for ...:\n",
    "        ...\n",
    "\n",
    "    # return the resampled statistic\n",
    "    return bootstrap_stats\n",
    "\n",
    "mt1_resampled_scores = bootstrap_stats(class_sample, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Question 3: Make a histogram of the resampled statistics\n",
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Question 4: Calculate a 95% confidence interval.\n",
    "# Hint: use the percentile function! It takes in 2 arguments,\n",
    "# the percent and the array of values\n",
    "\n",
    "lower_bound = ...\n",
    "upper_bound = ...\n",
    "\n",
    "[lower_bound, upper_bound]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do we conclude about the MT1 score based on the interval above? \n",
    "\n",
    "Type your answer here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The true MT1 score:\n",
    "true_val = np.mean(mt1_scores.column(0))\n",
    "true_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Properties of intervals: what does confidence mean?\n",
    "\n",
    "def fast_intervals():\n",
    "    # Take a large, random sample without replacement (SRS)\n",
    "    our_large_sample = np.random.choice(mt1_scores.column(0), size = 60, replace = False)\n",
    "    scores = []\n",
    "    for i in np.arange(1000):\n",
    "        # Resample with replacement\n",
    "        sample = np.random.choice(our_large_sample, size = 60, replace = True)\n",
    "        # Calculate the resample statistic\n",
    "        scores.append(np.mean(sample))\n",
    "    # Generate an interval using percentiles\n",
    "    left, right = np.percentile(scores, 2.5), np.percentile(scores, 97.5)\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making some intervals and a graph; it'll take a sec\n",
    "intervals = [fast_intervals() for i in range(100)]\n",
    "bounds = zip(*intervals)\n",
    "\n",
    "plt.xlim(min(bounds[0]), max(bounds[1]));\n",
    "plt.ylim(0, 100);\n",
    "step = 0\n",
    "for interval in intervals:\n",
    "    plt.plot(interval, (step, step), color = \"gold\");\n",
    "    step += 4\n",
    "\n",
    "plt.axvline(true_val, color = \"navy\");\n",
    "plt.xlabel(\"MT1 Score Average\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captured = 0\n",
    "for i in intervals:\n",
    "    captured = captured + (i[0] <= true_val <= i[1]) # Did this interval capture the parameter?\n",
    "    \n",
    "captured # Number of intervals that got the parameter, out of 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually creating + checking many intervals can be computationally intensive\n",
    "# But in theory, if we made 10000 intervals, ? will capture true_val\n",
    "\n",
    "num_good_intervals = ... \n",
    "num_good_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis testing with confidence intervals\n",
    "\n",
    "Remember from a few weeks ago, we had a hunch that MT2 was significantly more difficult than MT1 in this dataset, and we proved it with a hypothesis test.  \n",
    "\n",
    "If it was more difficult, this would influence any further analysis we do with the data -- if the means were significantly different, we should not do a simple comparison between exam 1 and exam 2, since our analysis will reflect the difficulty of the exams moreso than an individual's improvement.\n",
    "\n",
    "So: let's figure out if there was a significant difference! Let's use a different approach - we can use hypothesis testing with a confidence interval. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imagine we have a sample of 60 students, or 2 lab sections. \n",
    "np.random.seed(12345);\n",
    "\n",
    "exams = Table().read_table(\"scores.csv\").sample(60, with_replacement = False)\n",
    "exams.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare the distributions.\n",
    "exams.hist([\"MT1 %\", \"MT2 %\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this cell, answer the following:**\n",
    "\n",
    "What is our test statistic?\n",
    "\n",
    "\n",
    "What is our null hypothesis?\n",
    "\n",
    "\n",
    "What is our alternative hypothesis?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, was there a difference between the two exams, given (MT2 - MT1)?\n",
    "# Q1: Calculate the observed statistic from the dataset. \n",
    "# Hint -- we did most of this for you already (look at exams)\n",
    "\n",
    "obs_diff = ...\n",
    "obs_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's go bootstrap! Let's do 1000 repetitions\n",
    "exam_diffs = exams.select(\"difference\")\n",
    "\n",
    "resamp_diff_means = bootstrap_stats(exam_diffs, 1000)\n",
    "resamp_diff_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3: Calculate a 90% interval for this data. \n",
    "# Bonus: what is our p-value cutoff/level of significance?\n",
    "\n",
    "lower = ...\n",
    "upper = ...\n",
    "\n",
    "[lower, upper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4: Finally, graph the distribution of resampled means.\n",
    "# use plt (matplotlib.pyplot) to show the bounds of the interval.\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5: What is our conclusion?\n",
    "# What does this mean for our data and our analysis?\n",
    "reject_null = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
